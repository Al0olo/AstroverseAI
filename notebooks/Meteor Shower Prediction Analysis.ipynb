{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meteor Shower Prediction Analysis\n",
    "\n",
    "This notebook analyzes the performance of our Meteor Shower prediction models (Random Forest and Gradient Boosting), visualizes historical and predicted meteor shower activities, and explores patterns in meteor shower occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from src.data_processing.data_loader import DataLoader\n",
    "from src.models.meteor_shower_predictor import MeteorShowerPredictor\n",
    "from src.models.gb_meteor_shower_predictor import GBMeteorShowerPredictor\n",
    "from src.evaluation.prediction_evaluator import evaluate_meteor_shower_predictions\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# List of major meteor showers we're analyzing\n",
    "SHOWERS = ['Perseids', 'Geminids', 'Leonids', 'Orionids', 'Quadrantids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader()\n",
    "meteor_data = loader.load_meteor_shower_data()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data = meteor_data[meteor_data['date'] < '2020-01-01']\n",
    "test_data = meteor_data[meteor_data['date'] >= '2020-01-01']\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Testing data shape: {test_data.shape}\")\n",
    "\n",
    "# Display sample of the data\n",
    "print(\"\\nSample of meteor shower data:\")\n",
    "print(meteor_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Historical Meteor Shower Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shower_intensity(data, shower):\n",
    "    shower_data = data[data['shower'] == shower]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(shower_data['date'], shower_data['intensity'], alpha=0.6)\n",
    "    plt.title(f'Historical Intensity of {shower} Meteor Shower')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Intensity (meteors per hour)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for shower in SHOWERS:\n",
    "    plot_shower_intensity(meteor_data, shower)\n",
    "    \n",
    "    # Calculate and display shower statistics\n",
    "    shower_stats = meteor_data[meteor_data['shower'] == shower]['intensity'].describe()\n",
    "    print(f\"\\nStatistics for {shower}:\")\n",
    "    print(shower_stats)\n",
    "    print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Meteor Shower Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = MeteorShowerPredictor()\n",
    "gb_model = GBMeteorShowerPredictor()\n",
    "\n",
    "rf_model.train(train_data)\n",
    "gb_model.train(train_data)\n",
    "\n",
    "print(\"Random Forest and Gradient Boosting models trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(rf_model, gb_model, test_data):\n",
    "    rf_predictions = rf_model.predict(test_data)\n",
    "    gb_predictions = gb_model.predict(test_data)\n",
    "    \n",
    "    rf_mse = mean_squared_error(test_data['intensity'], rf_predictions)\n",
    "    gb_mse = mean_squared_error(test_data['intensity'], gb_predictions)\n",
    "    \n",
    "    rf_r2 = r2_score(test_data['intensity'], rf_predictions)\n",
    "    gb_r2 = r2_score(test_data['intensity'], gb_predictions)\n",
    "    \n",
    "    print(\"Random Forest Model:\")\n",
    "    print(f\"Mean Squared Error: {rf_mse:.2f}\")\n",
    "    print(f\"R2 Score: {rf_r2:.2f}\")\n",
    "    \n",
    "    print(\"\\nGradient Boosting Model:\")\n",
    "    print(f\"Mean Squared Error: {gb_mse:.2f}\")\n",
    "    print(f\"R2 Score: {gb_r2:.2f}\")\n",
    "    \n",
    "    return rf_predictions, gb_predictions\n",
    "\n",
    "rf_predictions, gb_predictions = evaluate_models(rf_model, gb_model, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Predictions vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_vs_actual(test_data, rf_predictions, gb_predictions, shower):\n",
    "    shower_data = test_data[test_data['shower'] == shower]\n",
    "    shower_rf_pred = rf_predictions[test_data['shower'] == shower]\n",
    "    shower_gb_pred = gb_predictions[test_data['shower'] == shower]\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.scatter(shower_data['date'], shower_data['intensity'], alpha=0.6, label='Actual')\n",
    "    plt.scatter(shower_data['date'], shower_rf_pred, alpha=0.6, label='Random Forest')\n",
    "    plt.scatter(shower_data['date'], shower_gb_pred, alpha=0.6, label='Gradient Boosting')\n",
    "    plt.title(f'Actual vs Predicted Intensity for {shower}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Intensity (meteors per hour)')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for shower in SHOWERS:\n",
    "    plot_predictions_vs_actual(test_data, rf_predictions, gb_predictions, shower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Prediction Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_errors(test_data, rf_predictions, gb_predictions):\n",
    "    rf_errors = test_data['intensity'] - rf_predictions\n",
    "    gb_errors = test_data['intensity'] - gb_predictions\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(rf_errors, kde=True, label='Random Forest')\n",
    "    sns.histplot(gb_errors, kde=True, label='Gradient Boosting')\n",
    "    plt.title('Distribution of Prediction Errors')\n",
    "    plt.xlabel('Error (Actual - Predicted)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Error Statistics:\")\n",
    "    print(f\"Random Forest - Mean Error: {rf_errors.mean():.2f}, Std Dev: {rf_errors.std():.2f}\")\n",
    "    print(f\"Gradient Boosting - Mean Error: {gb_errors.mean():.2f}, Std Dev: {gb_errors.std():.2f}\")\n",
    "\n",
    "analyze_errors(test_data, rf_predictions, gb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predict Future Meteor Showers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_showers(rf_model, gb_model, start_date, end_date):\n",
    "    future_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    future_data = pd.DataFrame({'date': future_dates})\n",
    "    \n",
    "    rf_predictions = rf_model.predict(future_data)\n",
    "    gb_predictions = gb_model.predict(future_data)\n",
    "    \n",
    "    future_data['rf_intensity'] = rf_predictions\n",
    "    future_data['gb_intensity'] = gb_predictions\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(future_data['date'], future_data['rf_intensity'], label='Random Forest')\n",
    "    plt.plot(future_data['date'], future_data['gb_intensity'], label='Gradient Boosting')\n",
    "    plt.title(f'Predicted Meteor Shower Activity ({start_date} to {end_date})')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Predicted Intensity (meteors per hour)')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find peaks in predictions\n",
    "    rf_peaks = future_data[future_data['rf_intensity'] > future_data['rf_intensity'].quantile(0.95)]\n",
    "    gb_peaks = future_data[future_data['gb_intensity'] > future_data['gb_intensity'].quantile(0.95)]\n",
    "    \n",
    "    print(\"Predicted peak meteor shower activities:\")\n",
    "    print(\"Random Forest Model:\")\n",
    "    print(rf_peaks[['date', 'rf_intensity']].sort_values('rf_intensity', ascending=False).head())\n",
    "    print(\"\\nGradient Boosting Model:\")\n",
    "    print(gb_peaks[['date', 'gb_intensity']].sort_values('gb_intensity', ascending=False).head())\n",
    "\n",
    "predict_future_showers(rf_model, gb_model, '2025-01-01', '2025-12-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze Meteor Shower Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_shower_patterns(data):\n",
    "    yearly_peaks = data.groupby(['shower', data['date'].dt.year])['intensity'].max().unstack()\n",
    "    \n    plt.figure(figsize=(15, 8))\n",
    "    sns.heatmap(yearly_peaks, cmap='YlOrRd', annot=True, fmt='.0f')\n",
    "    plt.title('Yearly Peak Intensities of Meteor Showers')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Meteor Shower')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze periodicity\n",
    "    for shower in SHOWERS:\n",
    "        shower_data = data[data['shower'] == shower]\n",
    "        peak_years = shower_data.groupby(shower_data['date'].dt.year)['intensity'].idxmax()\n",
    "        peak_intervals = peak_years.diff().dt.days / 365.25  # Convert to years\n",
    "        \n",
    "        print(f\"\\n{shower} - Average years between peaks: {peak_intervals.mean():.2f}\")\n",
    "        print(f\"Standard deviation: {peak_intervals.std():.2f}\")\n",
    "\n",
    "analyze_shower_patterns(meteor_data)\n",
    "\n",
    "print(\"\\nKey observations from the shower pattern analysis:\")\n",
    "print(\"1. [Your observation about periodicity of different showers]\")\n",
    "print(\"2. [Your observation about variations in peak intensities over years]\")\n",
    "print(\"3. [Any other interesting patterns or anomalies you notice]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, model_name):\n",
    "    feature_importance = model.feature_importances_\n",
    "    feature_names = model.feature_names_\n",
    "    \n",
    "    importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=importance_df)\n",
    "    plt.title(f'Feature Importance - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance(rf_model, 'Random Forest')\n",
    "plot_feature_importance(gb_model, 'Gradient Boosting')\n",
    "\n",
    "print(\"Key insights from feature importance analysis:\")\n",
    "print(\"1. [Your observation about top features for predicting meteor shower intensity]\")\n",
    "print(\"2. [Comparison of important features between RF and GB models]\")\n",
    "print(\"3. [Any surprising or counterintuitive results in feature importance]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Performance Across Different Showers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_shower(test_data, rf_predictions, gb_predictions):\n",
    "    results = []\n",
    "    for shower in SHOWERS:\n",
    "        shower_mask = test_data['shower'] == shower\n",
    "        shower_actual = test_data.loc[shower_mask, 'intensity']\n",
    "        shower_rf_pred = rf_predictions[shower_mask]\n",
    "        shower_gb_pred = gb_predictions[shower_mask]\n",
    "        \n",
    "        rf_mse = mean_squared_error(shower_actual, shower_rf_pred)\n",
    "        gb_mse = mean_squared_error(shower_actual, shower_gb_pred)\n",
    "        rf_r2 = r2_score(shower_actual, shower_rf_pred)\n",
    "        gb_r2 = r2_score(shower_actual, shower_gb_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'Shower': shower,\n",
    "            'RF_MSE': rf_mse,\n",
    "            'GB_MSE': gb_mse,\n",
    "            'RF_R2': rf_r2,\n",
    "            'GB_R2': gb_r2\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Shower', y='value', hue='variable', \n",
    "                data=pd.melt(results_df, ['Shower'], var_name='variable', value_name='value'))\n",
    "    plt.title('Model Performance Across Different Meteor Showers')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(results_df)\n",
    "    \n",
    "    print(\"\\nKey observations on model performance across showers:\")\n",
    "    print(\"1. [Your observation about which showers are predicted most accurately]\")\n",
    "    print(\"2. [Comparison of RF and GB performance for different showers]\")\n",
    "    print(\"3. [Any patterns in prediction difficulty across showers]\")\n",
    "\n",
    "evaluate_per_shower(test_data, rf_predictions, gb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion and Future Work\n",
    "\n",
    "In this notebook, we've conducted a comprehensive analysis of meteor shower predictions using both Random Forest and Gradient Boosting models. Key findings include:\n",
    "\n",
    "1. [Summarize overall model performance, comparing RF and GB]\n",
    "2. [Discuss any common patterns or interesting differences in meteor shower occurrences]\n",
    "3. [Highlight any particularly challenging aspects of meteor shower prediction]\n",
    "4. [Mention any unexpected results or insights gained from the analysis]\n",
    "\n",
    "Future work could include:\n",
    "1. Incorporating additional astronomical features to improve prediction accuracy, such as solar activity or interplanetary dust distribution.\n",
    "2. Developing a hybrid model that combines the strengths of both Random Forest and Gradient Boosting approaches.\n",
    "3. Extending the model to predict not just intensity, but also the duration and radiant position of meteor showers.\n",
    "4. Investigating the potential for real-time updating of predictions based on early observed data during a meteor shower event.\n",
    "5. Exploring the use of deep learning models, particularly for capturing long-term dependencies in meteor shower patterns.\n",
    "6. Correlating meteor shower predictions with other astronomical phenomena predicted by our system (e.g., planetary positions, solar activity).\n",
    "\n",
    "This analysis demonstrates the potential of machine learning techniques in predicting complex astronomical phenomena like meteor showers. It provides a foundation for further research into space weather forecasting and our understanding of small body dynamics in the solar system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}